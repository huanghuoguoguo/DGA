#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆåŒæ„TCBAM-MoEæ¨¡å‹å®ç°
æ”¹è¿›é—¨æ§ç½‘ç»œå’Œè´Ÿè½½å‡è¡¡æœºåˆ¶
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from core.base_model import BaseModel
from models.implementations.tcbam_models import (
    ChannelAttention, SpatialAttention, CBAMBlock, 
    DPCNNBlock, BiLSTMAttention
)


class EnhancedTCBAMExpert(nn.Module):
    """å¢å¼ºç‰ˆTCBAMä¸“å®¶æ¨¡å—"""
    
    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, 
                 num_filters=128, num_heads=8, num_layers=2, dropout=0.1, expert_id=0):
        super(EnhancedTCBAMExpert, self).__init__()
        
        self.expert_id = expert_id
        self.embed_dim = embed_dim
        self.hidden_dim = hidden_dim
        self.num_filters = num_filters
        
        # ä¸“å®¶ç‰¹å¼‚æ€§åˆå§‹åŒ– - æ¯ä¸ªä¸“å®¶æœ‰ä¸åŒçš„åˆå§‹åŒ–ç­–ç•¥
        self.expert_bias = nn.Parameter(torch.randn(1) * 0.1)
        
        # åµŒå…¥å±‚
        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)
        self.pos_encoding = nn.Parameter(torch.randn(1000, embed_dim))
        
        # Transformerç¼–ç å™¨ - æ¯ä¸ªä¸“å®¶æœ‰ä¸åŒçš„å±‚æ•°
        actual_layers = max(1, num_layers + (expert_id - 2))  # ä¸“å®¶0:1å±‚, ä¸“å®¶1:2å±‚, ä¸“å®¶2:3å±‚, ä¸“å®¶3:4å±‚
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, 
            nhead=num_heads, 
            dim_feedforward=embed_dim * 4,
            dropout=dropout,
            batch_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=actual_layers)
        
        # CNNåˆ†æ”¯1 (kernel_size=2) - ä¸“å®¶0å’Œ1æ›´å…³æ³¨çŸ­æ¨¡å¼
        if expert_id < 2:
            self.conv1_k2 = nn.Conv1d(embed_dim, num_filters, kernel_size=2, padding=1)
            self.conv2_k2 = nn.Conv1d(num_filters, num_filters, kernel_size=2, padding=1)
        else:
            self.conv1_k2 = nn.Conv1d(embed_dim, num_filters, kernel_size=3, padding=1)
            self.conv2_k2 = nn.Conv1d(num_filters, num_filters, kernel_size=3, padding=1)
            
        self.cbam1 = CBAMBlock(num_filters)
        self.dpcnn1 = DPCNNBlock(num_filters, num_filters, 2 if expert_id < 2 else 3)
        self.bilstm_att1 = BiLSTMAttention(num_filters, hidden_dim//2, num_filters)
        
        # CNNåˆ†æ”¯2 (kernel_size=3) - ä¸“å®¶2å’Œ3æ›´å…³æ³¨é•¿æ¨¡å¼
        if expert_id >= 2:
            self.conv1_k3 = nn.Conv1d(embed_dim, num_filters, kernel_size=4, padding=2)
            self.conv2_k3 = nn.Conv1d(num_filters, num_filters, kernel_size=4, padding=2)
            self.conv3_k3 = nn.Conv1d(num_filters, num_filters, kernel_size=4, padding=2)
        else:
            self.conv1_k3 = nn.Conv1d(embed_dim, num_filters, kernel_size=3, padding=1)
            self.conv2_k3 = nn.Conv1d(num_filters, num_filters, kernel_size=3, padding=1)
            self.conv3_k3 = nn.Conv1d(num_filters, num_filters, kernel_size=3, padding=1)
            
        self.cbam2 = CBAMBlock(num_filters)
        self.dpcnn2 = DPCNNBlock(num_filters, num_filters, 3 if expert_id < 2 else 4)
        self.bilstm_att2 = BiLSTMAttention(num_filters, hidden_dim//2, num_filters)
        
        # ç‰¹å¾èåˆ - æ¯ä¸ªä¸“å®¶æœ‰ä¸åŒçš„èåˆç­–ç•¥
        fusion_dim = num_filters * 4
        if expert_id % 2 == 0:  # ä¸“å®¶0,2ä½¿ç”¨æ›´æ·±çš„èåˆç½‘ç»œ
            self.feature_fusion = nn.Sequential(
                nn.Linear(fusion_dim, num_filters * 3),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(num_filters * 3, num_filters * 2),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(num_filters * 2, num_filters),
                nn.ReLU(),
                nn.Dropout(dropout)
            )
        else:  # ä¸“å®¶1,3ä½¿ç”¨è¾ƒæµ…çš„èåˆç½‘ç»œ
            self.feature_fusion = nn.Sequential(
                nn.Linear(fusion_dim, num_filters * 2),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(num_filters * 2, num_filters),
                nn.ReLU(),
                nn.Dropout(dropout)
            )
        
        self.dropout = nn.Dropout(dropout)
        
        # ä¸“å®¶ç‰¹å¼‚æ€§å‚æ•°åˆå§‹åŒ–
        self._init_expert_weights()
        
    def _init_expert_weights(self):
        """ä¸“å®¶ç‰¹å¼‚æ€§æƒé‡åˆå§‹åŒ–"""
        for name, param in self.named_parameters():
            if 'weight' in name and len(param.shape) >= 2:
                # æ¯ä¸ªä¸“å®¶ä½¿ç”¨ä¸åŒçš„åˆå§‹åŒ–ç­–ç•¥
                if self.expert_id == 0:
                    nn.init.xavier_uniform_(param)
                elif self.expert_id == 1:
                    nn.init.kaiming_uniform_(param)
                elif self.expert_id == 2:
                    nn.init.xavier_normal_(param)
                else:
                    nn.init.kaiming_normal_(param)
    
    def forward(self, x):
        batch_size, seq_len = x.shape
        
        # åµŒå…¥ + ä½ç½®ç¼–ç 
        embedded = self.embedding(x)
        if seq_len <= self.pos_encoding.size(0):
            embedded = embedded + self.pos_encoding[:seq_len].unsqueeze(0)
        
        # æ·»åŠ ä¸“å®¶åç½®
        embedded = embedded + self.expert_bias
        
        # Transformerç¼–ç 
        transformer_out = self.transformer_encoder(embedded)
        
        # è½¬æ¢ä¸ºCNNè¾“å…¥æ ¼å¼
        cnn_input = transformer_out.transpose(1, 2)  # (batch_size, embed_dim, seq_len)
        
        # CNNåˆ†æ”¯1
        conv1_out = F.relu(self.conv1_k2(cnn_input))
        conv1_out = F.relu(self.conv2_k2(conv1_out))
        conv1_out = self.cbam1(conv1_out)
        conv1_out = self.dpcnn1(conv1_out)
        
        # è½¬æ¢ä¸ºBiLSTMè¾“å…¥æ ¼å¼
        conv1_lstm_input = conv1_out.transpose(1, 2)
        conv1_final = self.bilstm_att1(conv1_lstm_input)
        
        # CNNåˆ†æ”¯2
        conv2_out = F.relu(self.conv1_k3(cnn_input))
        conv2_out = F.relu(self.conv2_k3(conv2_out))
        conv2_out = F.relu(self.conv3_k3(conv2_out))
        conv2_out = self.cbam2(conv2_out)
        conv2_out = self.dpcnn2(conv2_out)
        
        # è½¬æ¢ä¸ºBiLSTMè¾“å…¥æ ¼å¼
        conv2_lstm_input = conv2_out.transpose(1, 2)
        conv2_final = self.bilstm_att2(conv2_lstm_input)
        
        # å…¨å±€æ± åŒ–
        transformer_pooled = torch.mean(transformer_out, dim=1)
        
        # ç‰¹å¾æ‹¼æ¥
        combined_features = torch.cat([
            transformer_pooled,
            conv1_final,
            conv2_final,
            transformer_pooled * 0.5  # æ·»åŠ é¢å¤–çš„å…¨å±€ç‰¹å¾
        ], dim=1)
        
        # ç‰¹å¾èåˆ
        fused_features = self.feature_fusion(combined_features)
        fused_features = self.dropout(fused_features)
        
        return fused_features


class EnhancedGatingNetwork(nn.Module):
    """å¢å¼ºç‰ˆé—¨æ§ç½‘ç»œ"""
    
    def __init__(self, input_dim, num_experts, hidden_dim=256):
        super(EnhancedGatingNetwork, self).__init__()
        self.num_experts = num_experts
        
        # å¤šå±‚æ„ŸçŸ¥æœºé—¨æ§ç½‘ç»œ
        self.gate = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.LayerNorm(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, hidden_dim // 4),
            nn.ReLU(),
            nn.Linear(hidden_dim // 4, num_experts)
        )
        
        # ç‰¹å¾åˆ†æç½‘ç»œ - åˆ†æè¾“å…¥ç‰¹å¾çš„ç±»å‹
        self.feature_analyzer = nn.Sequential(
            nn.Linear(input_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 4)  # 4ç§ç‰¹å¾ç±»å‹ï¼šå­—ç¬¦çº§ã€å­—å…¸çº§ã€ç»“æ„çº§ã€æ··åˆçº§
        )
        
        # ä¸“å®¶-ç‰¹å¾ç±»å‹æ˜ å°„æƒé‡
        self.expert_feature_weights = nn.Parameter(torch.randn(num_experts, 4))
        
        # æ¸©åº¦å‚æ•°ç”¨äºæ§åˆ¶é—¨æ§çš„é”åº¦
        self.temperature = nn.Parameter(torch.ones(1))
        
    def forward(self, x):
        # x shape: (batch_size, seq_len, embed_dim)
        batch_size = x.size(0)
        
        # å¤šç§æ± åŒ–ç­–ç•¥
        mean_pooled = torch.mean(x, dim=1)  # å…¨å±€å¹³å‡æ± åŒ–
        max_pooled, _ = torch.max(x, dim=1)  # å…¨å±€æœ€å¤§æ± åŒ–
        
        # æ³¨æ„åŠ›æ± åŒ–
        attention_weights = F.softmax(torch.sum(x, dim=-1), dim=-1)  # (batch_size, seq_len)
        attention_pooled = torch.sum(x * attention_weights.unsqueeze(-1), dim=1)
        
        # ç»„åˆç‰¹å¾
        combined_features = torch.cat([mean_pooled, max_pooled, attention_pooled], dim=-1)
        
        # åŸºç¡€é—¨æ§æƒé‡
        gate_logits = self.gate(mean_pooled)  # (batch_size, num_experts)
        
        # ç‰¹å¾ç±»å‹åˆ†æ
        feature_type_logits = self.feature_analyzer(mean_pooled)  # (batch_size, 4)
        feature_type_probs = F.softmax(feature_type_logits, dim=-1)
        
        # ä¸“å®¶-ç‰¹å¾ç±»å‹åŒ¹é…åˆ†æ•°
        expert_feature_scores = torch.matmul(feature_type_probs, self.expert_feature_weights.t())  # (batch_size, num_experts)
        
        # ç»„åˆé—¨æ§åˆ†æ•°
        final_gate_logits = gate_logits + expert_feature_scores
        
        # ä½¿ç”¨æ¸©åº¦å‚æ•°è°ƒèŠ‚é”åº¦
        final_gate_logits = final_gate_logits / torch.clamp(self.temperature, min=0.1, max=10.0)
        
        # è®¡ç®—æœ€ç»ˆæƒé‡
        gate_weights = F.softmax(final_gate_logits, dim=-1)
        
        return gate_weights, feature_type_probs


class EnhancedHomogeneousTCBAMMoE(BaseModel):
    """å¢å¼ºç‰ˆåŒæ„TCBAM-MoEæ¨¡å‹"""
    
    def __init__(self, vocab_size, num_classes=2, num_experts=4, 
                 embed_dim=128, hidden_dim=128, num_filters=128, 
                 num_heads=8, num_layers=2, dropout=0.1):
        super(EnhancedHomogeneousTCBAMMoE, self).__init__(vocab_size, num_classes)
        
        self.num_experts = num_experts
        self.embed_dim = embed_dim
        
        # å…±äº«åµŒå…¥å±‚
        self.shared_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)
        self.pos_encoding = nn.Parameter(torch.randn(1000, embed_dim))
        
        # å¢å¼ºé—¨æ§ç½‘ç»œ
        self.gating_network = EnhancedGatingNetwork(embed_dim, num_experts)
        
        # å¤šä¸ªå¢å¼ºTCBAMä¸“å®¶
        self.experts = nn.ModuleList([
            EnhancedTCBAMExpert(
                vocab_size=vocab_size,
                embed_dim=embed_dim,
                hidden_dim=hidden_dim,
                num_filters=num_filters,
                num_heads=num_heads,
                num_layers=num_layers,
                dropout=dropout,
                expert_id=i
            ) for i in range(num_experts)
        ])
        
        # æœ€ç»ˆåˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Linear(num_filters, num_filters // 2),
            nn.LayerNorm(num_filters // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(num_filters // 2, num_filters // 4),
            nn.ReLU(),
            nn.Linear(num_filters // 4, num_classes)
        )
        
        # è´Ÿè½½å‡è¡¡æŸå¤±æƒé‡
        self.load_balance_weight = 0.01
        self.diversity_weight = 0.01
        
        # ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡
        self.expert_usage_count = torch.zeros(num_experts)
        self.total_samples = 0
        
    def forward(self, x):
        batch_size = x.size(0)
        
        # å…±äº«åµŒå…¥
        embedded = self.shared_embedding(x)
        seq_len = embedded.size(1)
        if seq_len <= self.pos_encoding.size(0):
            embedded = embedded + self.pos_encoding[:seq_len].unsqueeze(0)
        
        # é—¨æ§ç½‘ç»œ
        gate_weights, feature_type_probs = self.gating_network(embedded)
        
        # ä¸“å®¶è¾“å‡º
        expert_outputs = []
        for expert in self.experts:
            expert_out = expert(x)
            expert_outputs.append(expert_out)
        
        # å †å ä¸“å®¶è¾“å‡º
        expert_outputs = torch.stack(expert_outputs, dim=1)  # (batch_size, num_experts, num_filters)
        
        # åŠ æƒç»„åˆ
        gate_weights_expanded = gate_weights.unsqueeze(-1)  # (batch_size, num_experts, 1)
        combined_output = torch.sum(expert_outputs * gate_weights_expanded, dim=1)  # (batch_size, num_filters)
        
        # åˆ†ç±»
        logits = self.classifier(combined_output)
        
        # æ›´æ–°ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡
        if self.training:
            with torch.no_grad():
                expert_usage = torch.sum(gate_weights, dim=0)
                self.expert_usage_count += expert_usage.cpu()
                self.total_samples += batch_size
        
        # å­˜å‚¨ä¸­é—´ç»“æœç”¨äºæŸå¤±è®¡ç®—
        self.last_gate_weights = gate_weights
        self.last_expert_outputs = expert_outputs
        self.last_feature_type_probs = feature_type_probs
        
        return logits
    
    def get_load_balance_loss(self):
        """è®¡ç®—è´Ÿè½½å‡è¡¡æŸå¤±"""
        if not hasattr(self, 'last_gate_weights'):
            return torch.tensor(0.0)
        
        # è®¡ç®—ä¸“å®¶ä½¿ç”¨çš„æ–¹å·®
        expert_usage = torch.mean(self.last_gate_weights, dim=0)
        target_usage = 1.0 / self.num_experts
        balance_loss = torch.var(expert_usage) + torch.mean((expert_usage - target_usage) ** 2)
        
        return balance_loss * self.load_balance_weight
    
    def get_diversity_loss(self):
        """è®¡ç®—ä¸“å®¶å¤šæ ·æ€§æŸå¤±"""
        if not hasattr(self, 'last_expert_outputs'):
            return torch.tensor(0.0)
        
        # è®¡ç®—ä¸“å®¶è¾“å‡ºçš„ç›¸ä¼¼æ€§
        expert_outputs = self.last_expert_outputs  # (batch_size, num_experts, num_filters)
        
        # è®¡ç®—ä¸“å®¶é—´çš„ä½™å¼¦ç›¸ä¼¼æ€§
        normalized_outputs = F.normalize(expert_outputs, p=2, dim=-1)
        similarity_matrix = torch.matmul(normalized_outputs, normalized_outputs.transpose(-1, -2))
        
        # å»é™¤å¯¹è§’çº¿å…ƒç´ ï¼ˆè‡ªç›¸ä¼¼æ€§ï¼‰
        mask = torch.eye(self.num_experts, device=similarity_matrix.device).unsqueeze(0)
        similarity_matrix = similarity_matrix * (1 - mask)
        
        # å¤šæ ·æ€§æŸå¤±ï¼šé¼“åŠ±ä¸“å®¶è¾“å‡ºä¸åŒ
        diversity_loss = torch.mean(torch.abs(similarity_matrix))
        
        return diversity_loss * self.diversity_weight
    
    def get_expert_usage_stats(self):
        """è·å–ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡"""
        if self.total_samples == 0:
            return None
        
        usage_percentages = (self.expert_usage_count / self.total_samples * 100).tolist()
        return {
            'expert_usage_percentages': usage_percentages,
            'total_samples': self.total_samples,
            'usage_variance': float(torch.var(self.expert_usage_count / self.total_samples))
        }
    
    def print_model_info(self):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        print(f"ğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
        print(f"  æ€»å‚æ•°é‡: {total_params:,}")
        print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"  æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")
        print(f"  è¯æ±‡è¡¨å¤§å°: {self.vocab_size}")
        print(f"  ç±»åˆ«æ•°: {self.num_classes}")
        print(f"  ä¸“å®¶æ•°é‡: {self.num_experts}")
        print(f"  ä¸“å®¶ç±»å‹: Enhanced TCBAM (åŒæ„å¢å¼º)")
        print(f"  è´Ÿè½½å‡è¡¡æƒé‡: {self.load_balance_weight}")
        print(f"  å¤šæ ·æ€§æŸå¤±æƒé‡: {self.diversity_weight}")
    
    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯å­—å…¸"""
        total_params = sum(p.numel() for p in self.parameters())
        return {
            'model_name': 'EnhancedHomogeneousTCBAMMoE',
            'total_params': total_params,
            'vocab_size': self.vocab_size,
            'num_classes': self.num_classes,
            'num_experts': self.num_experts,
            'embed_dim': self.embed_dim
        }