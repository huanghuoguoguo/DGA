#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆMoEè®­ç»ƒå™¨
æ”¯æŒè´Ÿè½½å‡è¡¡æŸå¤±å’Œå¤šæ ·æ€§æŸå¤±
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import time
from typing import Dict, Any, Optional
from tqdm import tqdm
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from .base_model import ModelTrainer


class EnhancedMoETrainer(ModelTrainer):
    """å¢å¼ºç‰ˆMoEè®­ç»ƒå™¨"""
    
    def __init__(self, model, device, load_balance_weight=0.01, diversity_weight=0.01):
        super().__init__(model, device)
        self.load_balance_weight = load_balance_weight
        self.diversity_weight = diversity_weight
        
    def train(self, train_loader: DataLoader, val_loader: DataLoader, 
              num_epochs: int = 20, learning_rate: float = 0.001, 
              weight_decay: float = 1e-4, patience: int = 5, 
              save_path: str = None) -> Dict[str, Any]:
        """
        è®­ç»ƒæ¨¡å‹
        """
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ {self.model.__class__.__name__}...")
        
        # è®¾ç½®ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)
        criterion = nn.CrossEntropyLoss()
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='max', factor=0.5, patience=3
        )
        
        # è®­ç»ƒå†å²
        train_losses = []
        train_accuracies = []
        val_losses = []
        val_accuracies = []
        
        best_val_accuracy = 0.0
        patience_counter = 0
        
        start_time = time.time()
        
        for epoch in range(num_epochs):
            # è®­ç»ƒé˜¶æ®µ
            self.model.train()
            train_loss = 0.0
            train_correct = 0
            train_total = 0
            
            train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} - Training")
            
            for batch_idx, (data, target) in enumerate(train_pbar):
                data, target = data.to(self.device), target.to(self.device)
                
                optimizer.zero_grad()
                
                # å‰å‘ä¼ æ’­
                output = self.model(data)
                
                # åŸºç¡€åˆ†ç±»æŸå¤±
                classification_loss = criterion(output, target)
                
                # æ€»æŸå¤±
                total_loss = classification_loss
                
                # æ·»åŠ MoEç‰¹æœ‰çš„æŸå¤±
                if hasattr(self.model, 'get_load_balance_loss'):
                    load_balance_loss = self.model.get_load_balance_loss()
                    total_loss += load_balance_loss
                
                if hasattr(self.model, 'get_diversity_loss'):
                    diversity_loss = self.model.get_diversity_loss()
                    total_loss += diversity_loss
                
                # åå‘ä¼ æ’­
                total_loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                
                optimizer.step()
                
                # ç»Ÿè®¡
                train_loss += total_loss.item()
                _, predicted = torch.max(output.data, 1)
                train_total += target.size(0)
                train_correct += (predicted == target).sum().item()
                
                # æ›´æ–°è¿›åº¦æ¡
                current_acc = 100. * train_correct / train_total
                train_pbar.set_postfix({
                    'Loss': f'{total_loss.item():.4f}',
                    'Acc': f'{current_acc:.2f}%'
                })
            
            # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
            epoch_train_loss = train_loss / len(train_loader)
            epoch_train_accuracy = 100. * train_correct / train_total
            
            train_losses.append(epoch_train_loss)
            train_accuracies.append(epoch_train_accuracy)
            
            # éªŒè¯é˜¶æ®µ
            val_results = self.evaluate(val_loader)
            epoch_val_loss = val_results['loss']
            epoch_val_accuracy = val_results['accuracy'] * 100
            
            val_losses.append(epoch_val_loss)
            val_accuracies.append(epoch_val_accuracy)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step(epoch_val_accuracy)
            
            # æ‰“å°epochç»“æœ
            print(f"Epoch {epoch+1}/{num_epochs}: "
                  f"Train Acc: {epoch_train_accuracy:.2f}%, "
                  f"Val Acc: {epoch_val_accuracy:.2f}%, "
                  f"Train Loss: {epoch_train_loss:.4f}, "
                  f"Val Loss: {epoch_val_loss:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if epoch_val_accuracy > best_val_accuracy:
                best_val_accuracy = epoch_val_accuracy
                patience_counter = 0
                if save_path:
                    torch.save(self.model.state_dict(), save_path)
                    print(f"  âœ… æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_accuracy:.2f}%ï¼Œæ¨¡å‹å·²ä¿å­˜")
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print(f"  â¹ï¸ æ—©åœï¼šéªŒè¯å‡†ç¡®ç‡è¿ç»­{patience}è½®æœªæ”¹å–„")
                    break
            
            # æ‰“å°ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if hasattr(self.model, 'get_expert_usage_stats') and (epoch + 1) % 5 == 0:
                stats = self.model.get_expert_usage_stats()
                if stats:
                    print(f"  ğŸ“Š ä¸“å®¶ä½¿ç”¨ç‡: {[f'{p:.1f}%' for p in stats['expert_usage_percentages']]}")
                    print(f"  ğŸ“Š ä½¿ç”¨æ–¹å·®: {stats['usage_variance']:.4f}")
        
        training_time = time.time() - start_time
        print(f"è®­ç»ƒå®Œæˆï¼ç”¨æ—¶: {training_time:.2f}ç§’")
        
        return {
            'train_losses': train_losses,
            'train_accuracies': train_accuracies,
            'val_losses': val_losses,
            'val_accuracies': val_accuracies,
            'best_val_accuracy': best_val_accuracy,
            'training_time': training_time,
            'final_lr': optimizer.param_groups[0]['lr']
        }
    
    def evaluate(self, data_loader: DataLoader) -> Dict[str, float]:
        """
        è¯„ä¼°æ¨¡å‹
        """
        self.model.eval()
        total_loss = 0.0
        all_predictions = []
        all_targets = []
        inference_times = []
        
        criterion = nn.CrossEntropyLoss()
        
        with torch.no_grad():
            eval_pbar = tqdm(data_loader, desc="Evaluating")
            for data, target in eval_pbar:
                data, target = data.to(self.device), target.to(self.device)
                
                # æµ‹é‡æ¨ç†æ—¶é—´
                start_time = time.time()
                output = self.model(data)
                inference_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                inference_times.append(inference_time)
                
                # è®¡ç®—æŸå¤±
                loss = criterion(output, target)
                
                # æ·»åŠ MoEç‰¹æœ‰çš„æŸå¤±
                if hasattr(self.model, 'get_load_balance_loss'):
                    load_balance_loss = self.model.get_load_balance_loss()
                    loss += load_balance_loss
                
                if hasattr(self.model, 'get_diversity_loss'):
                    diversity_loss = self.model.get_diversity_loss()
                    loss += diversity_loss
                
                total_loss += loss.item()
                
                # é¢„æµ‹
                _, predicted = torch.max(output, 1)
                all_predictions.extend(predicted.cpu().numpy())
                all_targets.extend(target.cpu().numpy())
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(all_targets, all_predictions)
        precision = precision_score(all_targets, all_predictions, average='weighted', zero_division=0)
        recall = recall_score(all_targets, all_predictions, average='weighted', zero_division=0)
        f1 = f1_score(all_targets, all_predictions, average='weighted', zero_division=0)
        avg_loss = total_loss / len(data_loader)
        avg_inference_time = np.mean(inference_times)
        
        print(f"  å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"  ç²¾ç¡®ç‡: {precision:.4f}")
        print(f"  å¬å›ç‡: {recall:.4f}")
        print(f"  F1åˆ†æ•°: {f1:.4f}")
        print(f"  å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.2f}ms")
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'loss': avg_loss,
            'avg_inference_time': avg_inference_time
        }
    
    def analyze_expert_usage_detailed(self, data_loader: DataLoader) -> Optional[Dict[str, Any]]:
        """
        è¯¦ç»†åˆ†æä¸“å®¶ä½¿ç”¨æƒ…å†µ
        """
        if not hasattr(self.model, 'get_expert_usage_stats'):
            return None
        
        self.model.eval()
        
        # é‡ç½®ç»Ÿè®¡
        if hasattr(self.model, 'expert_usage_count'):
            self.model.expert_usage_count.zero_()
            self.model.total_samples = 0
        
        with torch.no_grad():
            for data, target in tqdm(data_loader, desc="Analyzing expert usage"):
                data, target = data.to(self.device), target.to(self.device)
                _ = self.model(data)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = self.model.get_expert_usage_stats()
        
        if stats:
            print(f"\nğŸ” ä¸“å®¶ä½¿ç”¨åˆ†æ:")
            for i, usage in enumerate(stats['expert_usage_percentages']):
                print(f"  ä¸“å®¶ {i}: {usage:.2f}%")
            print(f"  ä½¿ç”¨æ–¹å·®: {stats['usage_variance']:.4f}")
            print(f"  æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
            
            # è®¡ç®—è´Ÿè½½å‡è¡¡æŒ‡æ ‡
            usage_array = np.array(stats['expert_usage_percentages'])
            balance_score = 1.0 - (np.std(usage_array) / np.mean(usage_array))
            print(f"  è´Ÿè½½å‡è¡¡åˆ†æ•°: {balance_score:.4f} (è¶Šæ¥è¿‘1è¶Šå‡è¡¡)")
            
            stats['balance_score'] = balance_score
        
        return stats