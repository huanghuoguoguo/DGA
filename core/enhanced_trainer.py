#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DGA Detection - å¢å¼ºè®­ç»ƒå™¨
ä¸“é—¨æ”¯æŒç®€åŒ–æ”¹è¿›ç‰ˆMoEæ¨¡å‹çš„è®­ç»ƒ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import numpy as np
import time
from typing import Dict, Any, Tuple
from tqdm import tqdm

from .base_model import ModelTrainer


class EnhancedModelTrainer(ModelTrainer):
    """å¢å¼ºçš„æ¨¡å‹è®­ç»ƒå™¨ï¼Œä¸“é—¨æ”¯æŒç®€åŒ–æ”¹è¿›ç‰ˆMoE"""
    
    def __init__(self, model, device: str = 'cpu'):
        super().__init__(model, device)
        self.expert_usage_history = []
        self.loss_history = {'classification': [], 'load_balance': [], 'diversity': []}
        
    def train(self, 
              train_loader: DataLoader,
              val_loader: DataLoader,
              num_epochs: int = 20,
              learning_rate: float = 0.001,
              weight_decay: float = 1e-4,
              patience: int = 5,
              save_path: str = None) -> Dict[str, Any]:
        """è®­ç»ƒæ¨¡å‹ï¼ˆæ”¯æŒç®€åŒ–æ”¹è¿›ç‰ˆMoEï¼‰"""
        
        optimizer = optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=3)
        
        best_val_acc = 0
        patience_counter = 0
        training_history = {
            'train_acc': [], 'val_acc': [], 'train_loss': [], 'val_loss': [],
            'classification_loss': [], 'load_balance_loss': [], 'diversity_loss': [],
            'expert_usage': [], 'gate_weights_std': []
        }
        
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ {self.model.__class__.__name__}...")
        start_time = time.time()
        
        for epoch in range(1, num_epochs + 1):
            # è®­ç»ƒé˜¶æ®µ
            train_metrics = self._train_epoch_enhanced(train_loader, optimizer)
            
            # éªŒè¯é˜¶æ®µ
            val_metrics = self._validate_epoch_enhanced(val_loader)
            
            # è®°å½•å†å²
            training_history['train_acc'].append(train_metrics['accuracy'])
            training_history['val_acc'].append(val_metrics['accuracy'])
            training_history['train_loss'].append(train_metrics['total_loss'])
            training_history['val_loss'].append(val_metrics['loss'])
            training_history['classification_loss'].append(train_metrics.get('classification_loss', 0))
            training_history['load_balance_loss'].append(train_metrics.get('load_balance_loss', 0))
            training_history['diversity_loss'].append(train_metrics.get('diversity_loss', 0))
            training_history['expert_usage'].append(train_metrics.get('expert_usage', {}))
            training_history['gate_weights_std'].append(train_metrics.get('gate_weights_std', 0))
            
            # æ‰“å°è®­ç»ƒä¿¡æ¯
            print(f"Epoch {epoch}/{num_epochs}: "
                  f"Train Acc: {train_metrics['accuracy']:.2f}%, "
                  f"Val Acc: {val_metrics['accuracy']:.2f}%, "
                  f"Train Loss: {train_metrics['total_loss']:.4f}, "
                  f"Val Loss: {val_metrics['loss']:.4f}")
            
            # å¦‚æœæ˜¯ç®€åŒ–æ”¹è¿›ç‰ˆMoEæ¨¡å‹ï¼Œæ‰“å°è¯¦ç»†ä¿¡æ¯
            if hasattr(self.model, 'compute_total_loss'):
                print(f"  åˆ†ç±»æŸå¤±: {train_metrics.get('classification_loss', 0):.4f}, "
                      f"è´Ÿè½½å‡è¡¡: {train_metrics.get('load_balance_loss', 0):.4f}, "
                      f"å¤šæ ·æ€§: {train_metrics.get('diversity_loss', 0):.4f}")
                
                if 'expert_usage' in train_metrics and train_metrics['expert_usage']:
                    usage_str = ", ".join([f"{k}: {v:.1f}%" for k, v in train_metrics['expert_usage'].items()])
                    print(f"  ä¸“å®¶ä½¿ç”¨ç‡: {usage_str}")
                    print(f"  é—¨æ§æƒé‡æ ‡å‡†å·®: {train_metrics.get('gate_weights_std', 0):.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_metrics['accuracy'] > best_val_acc:
                best_val_acc = val_metrics['accuracy']
                patience_counter = 0
                if save_path:
                    torch.save(self.model.state_dict(), save_path)
                    print(f"  âœ… æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%ï¼Œæ¨¡å‹å·²ä¿å­˜")
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print(f"éªŒè¯å‡†ç¡®ç‡è¿ç»­{patience}ä¸ªepochæœªæå‡ï¼Œæå‰åœæ­¢è®­ç»ƒ")
                    break
            
            scheduler.step(val_metrics['accuracy'])
        
        training_time = time.time() - start_time
        print(f"è®­ç»ƒå®Œæˆï¼ç”¨æ—¶: {training_time:.2f}ç§’")
        
        return {
            'best_val_accuracy': best_val_acc,
            'training_time': training_time,
            'training_history': training_history,
            'final_epoch': epoch
        }
    
    def _train_epoch_enhanced(self, train_loader: DataLoader, optimizer) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepochï¼ˆå¢å¼ºç‰ˆï¼‰"""
        self.model.train()
        total_loss = 0
        total_classification_loss = 0
        total_load_balance_loss = 0
        total_diversity_loss = 0
        correct = 0
        total = 0
        
        # åŠ¨æ€è·å–ä¸“å®¶æ•°é‡å’Œåç§°
        if hasattr(self.model, 'expert_names'):
            expert_names = ['cnn', 'lstm', 'mamba', 'transformer']  # ä¿æŒåŸæœ‰åç§°
        else:
            expert_names = ['expert_' + str(i) for i in range(self.model.num_experts if hasattr(self.model, 'num_experts') else 4)]
        
        # ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡
        expert_usage_counts = {name: 0 for name in expert_names}
        gate_weights_all = []
        
        for data, target in tqdm(train_loader, desc="Training", leave=False):
            data, target = data.to(self.device), target.to(self.device)
            
            optimizer.zero_grad()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯MoEæ¨¡å‹
            if hasattr(self.model, 'compute_total_loss') or hasattr(self.model, 'expert_config'):
                # å¤„ç†ä¸åŒMoEæ¨¡å‹çš„è¿”å›æ ¼å¼
                if hasattr(self.model, 'expert_config') or hasattr(self.model, 'expert_names'):
                    # é«˜çº§MoEæ¨¡å‹æˆ–åŒæ„MoEæ¨¡å‹
                    result = self.model(data, return_gate_weights=True, return_expert_outputs=True)
                    if len(result) == 3:
                        logits, gate_weights, expert_outputs = result
                    else:
                        logits = result[0]
                        gate_weights = result[1] if len(result) > 1 else None
                        expert_outputs = result[2] if len(result) > 2 else None
                else:
                    # ç®€åŒ–æ”¹è¿›ç‰ˆMoEæ¨¡å‹
                    try:
                        logits, gate_weights, expert_outputs = self.model(data, return_expert_outputs=True)
                    except ValueError:
                        result = self.model(data, return_expert_outputs=True)
                        logits = result[0]
                        gate_weights = result[1] if len(result) > 1 else None
                        expert_outputs = result[2] if len(result) > 2 else None
                
                # è®¡ç®—æ€»æŸå¤±
                loss, loss_components = self.model.compute_total_loss(logits, target, gate_weights, expert_outputs)
                
                total_classification_loss += loss_components['classification_loss']
                total_load_balance_loss += loss_components['load_balance_loss']
                total_diversity_loss += loss_components['diversity_loss']
                
                # ç»Ÿè®¡ä¸“å®¶ä½¿ç”¨æƒ…å†µ
                dominant_experts = torch.argmax(gate_weights, dim=1)
                for expert_idx in dominant_experts:
                    if expert_idx < len(expert_names):
                        expert_usage_counts[expert_names[expert_idx]] += 1
                
                # æ”¶é›†é—¨æ§æƒé‡ç”¨äºåˆ†æ
                gate_weights_all.append(gate_weights.detach().cpu())
                
            else:
                # æ™®é€šæ¨¡å‹
                logits = self.model(data)
                loss = F.cross_entropy(logits, target)
            
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            total_loss += loss.item()
            pred = logits.argmax(dim=1)
            correct += pred.eq(target).sum().item()
            total += target.size(0)
        
        # è®¡ç®—ä¸“å®¶ä½¿ç”¨ç™¾åˆ†æ¯”
        expert_usage_percentages = {}
        if total > 0:
            for expert, count in expert_usage_counts.items():
                expert_usage_percentages[expert] = (count / total) * 100
        
        # è®¡ç®—é—¨æ§æƒé‡æ ‡å‡†å·®
        gate_weights_std = 0
        if gate_weights_all:
            all_weights = torch.cat(gate_weights_all, dim=0)
            gate_weights_std = torch.std(all_weights, dim=0).mean().item()
        
        result = {
            'total_loss': total_loss / len(train_loader),
            'accuracy': 100. * correct / total
        }
        
        # æ·»åŠ ç®€åŒ–æ”¹è¿›ç‰ˆMoEç‰¹å®šæŒ‡æ ‡
        if hasattr(self.model, 'compute_total_loss'):
            result.update({
                'classification_loss': total_classification_loss / len(train_loader),
                'load_balance_loss': total_load_balance_loss / len(train_loader),
                'diversity_loss': total_diversity_loss / len(train_loader),
                'expert_usage': expert_usage_percentages,
                'gate_weights_std': gate_weights_std
            })
        
        return result
    
    def _validate_epoch_enhanced(self, val_loader: DataLoader) -> Dict[str, float]:
        """éªŒè¯ä¸€ä¸ªepochï¼ˆå¢å¼ºç‰ˆï¼‰"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in tqdm(val_loader, desc="Validation", leave=False):
                data, target = data.to(self.device), target.to(self.device)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯MoEæ¨¡å‹
                if hasattr(self.model, 'compute_total_loss') or hasattr(self.model, 'expert_config'):
                    # å¤„ç†ä¸åŒMoEæ¨¡å‹çš„è¿”å›æ ¼å¼
                    if hasattr(self.model, 'expert_config') or hasattr(self.model, 'expert_names'):
                        # é«˜çº§MoEæ¨¡å‹æˆ–åŒæ„MoEæ¨¡å‹
                        result = self.model(data, return_gate_weights=True, return_expert_outputs=True)
                        if len(result) == 3:
                            logits, gate_weights, expert_outputs = result
                        else:
                            logits = result[0]
                            gate_weights = result[1] if len(result) > 1 else None
                            expert_outputs = result[2] if len(result) > 2 else None
                    else:
                        # ç®€åŒ–æ”¹è¿›ç‰ˆMoEæ¨¡å‹
                        try:
                            logits, gate_weights, expert_outputs = self.model(data, return_expert_outputs=True)
                        except ValueError:
                            result = self.model(data, return_expert_outputs=True)
                            logits = result[0]
                            gate_weights = result[1] if len(result) > 1 else None
                            expert_outputs = result[2] if len(result) > 2 else None
                else:
                    # æ™®é€šæ¨¡å‹
                    logits = self.model(data)
                
                loss = F.cross_entropy(logits, target)
                
                total_loss += loss.item()
                pred = logits.argmax(dim=1)
                correct += pred.eq(target).sum().item()
                total += target.size(0)
        
        return {
            'loss': total_loss / len(val_loader),
            'accuracy': 100. * correct / total
        }
    
    def analyze_expert_usage_detailed(self, test_loader: DataLoader) -> Dict[str, Any]:
        """è¯¦ç»†åˆ†æä¸“å®¶ä½¿ç”¨æƒ…å†µ"""
        if not hasattr(self.model, 'get_gate_weights'):
            return {"message": "æ¨¡å‹ä¸æ”¯æŒä¸“å®¶åˆ†æ"}
        
        print(f"ğŸ“Š è¯¦ç»†åˆ†æä¸“å®¶ä½¿ç”¨æƒ…å†µ...")
        
        self.model.eval()
        # åŠ¨æ€è·å–ä¸“å®¶æ•°é‡å’Œåç§°
        if hasattr(self.model, 'expert_names'):
            expert_names = self.model.expert_names
        else:
            # é»˜è®¤ä¸“å®¶åç§°
            expert_names = ['expert_' + str(i) for i in range(self.model.num_experts if hasattr(self.model, 'num_experts') else 4)]
        
        # ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡
        expert_usage = {name: 0 for name in expert_names}
        expert_accuracy = {name: [] for name in expert_names}
        expert_confidence = {name: [] for name in expert_names}
        gate_weights_history = []
        
        with torch.no_grad():
            for data, target in tqdm(test_loader, desc="Analyzing"):
                data, target = data.to(self.device), target.to(self.device)
                
                gate_weights = self.model.get_gate_weights(data)
                logits = self.model(data)
                pred = logits.argmax(dim=1)
                probs = F.softmax(logits, dim=1)
                
                gate_weights_history.append(gate_weights.cpu().numpy())
                
                # åˆ†ææ¯ä¸ªæ ·æœ¬çš„ä¸“å®¶ä½¿ç”¨æƒ…å†µ
                dominant_experts = torch.argmax(gate_weights, dim=1)
                max_probs = torch.max(probs, dim=1)[0]  # é¢„æµ‹ç½®ä¿¡åº¦
                
                for i, expert_idx in enumerate(dominant_experts):
                    if expert_idx < len(expert_names):
                        expert_name = expert_names[expert_idx]
                        expert_usage[expert_name] += 1
                        
                        # è®°å½•è¯¥ä¸“å®¶çš„å‡†ç¡®ç‡å’Œç½®ä¿¡åº¦
                        is_correct = (pred[i] == target[i]).item()
                        confidence = max_probs[i].item()
                        
                        expert_accuracy[expert_name].append(is_correct)
                        expert_confidence[expert_name].append(confidence)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_samples = sum(expert_usage.values())
        usage_percentages = {}
        accuracy_by_expert = {}
        confidence_by_expert = {}
        
        for expert, count in expert_usage.items():
            usage_percentages[expert] = (count / total_samples) * 100 if total_samples > 0 else 0
            
            if expert_accuracy[expert]:
                accuracy_by_expert[expert] = np.mean(expert_accuracy[expert]) * 100
                confidence_by_expert[expert] = np.mean(expert_confidence[expert])
            else:
                accuracy_by_expert[expert] = 0
                confidence_by_expert[expert] = 0
        
        # è®¡ç®—é—¨æ§æƒé‡ç»Ÿè®¡
        all_gate_weights = np.concatenate(gate_weights_history, axis=0)
        mean_gate_weights = np.mean(all_gate_weights, axis=0)
        std_gate_weights = np.std(all_gate_weights, axis=0)
        
        # è®¡ç®—ä¸“å®¶ä½¿ç”¨çš„å‡è¡¡æ€§
        usage_values = list(usage_percentages.values())
        usage_balance = 1.0 - (np.std(usage_values) / (np.mean(usage_values) + 1e-8))
        
        analysis_result = {
            'expert_usage_counts': expert_usage,
            'expert_usage_percentages': usage_percentages,
            'expert_accuracy': accuracy_by_expert,
            'expert_confidence': confidence_by_expert,
            'mean_gate_weights': {expert_names[i]: mean_gate_weights[i] for i in range(len(expert_names))},
            'std_gate_weights': {expert_names[i]: std_gate_weights[i] for i in range(len(expert_names))},
            'usage_balance_score': usage_balance,
            'total_samples': total_samples
        }
        
        # æ‰“å°è¯¦ç»†åˆ†æç»“æœ
        print(f"\nğŸ“ˆ è¯¦ç»†ä¸“å®¶ä½¿ç”¨åˆ†æç»“æœ:")
        print(f"{'ä¸“å®¶':<12} {'ä½¿ç”¨ç‡':<10} {'å‡†ç¡®ç‡':<10} {'ç½®ä¿¡åº¦':<10} {'å¹³å‡æƒé‡':<12} {'æƒé‡æ ‡å‡†å·®':<12}")
        print("-" * 75)
        
        for expert in expert_names:
            usage_pct = usage_percentages[expert]
            accuracy = accuracy_by_expert[expert]
            confidence = confidence_by_expert[expert]
            mean_weight = mean_gate_weights[expert_names.index(expert)]
            std_weight = std_gate_weights[expert_names.index(expert)]
            
            print(f"{expert.upper():<12} {usage_pct:<9.1f}% {accuracy:<9.1f}% {confidence:<9.3f} {mean_weight:<11.3f} {std_weight:<11.3f}")
        
        print(f"\nğŸ“Š ä¸“å®¶ä½¿ç”¨å‡è¡¡æ€§è¯„åˆ†: {usage_balance:.3f} (è¶Šæ¥è¿‘1è¶Šå‡è¡¡)")
        
        return analysis_result
    
    def get_training_insights(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒè¿‡ç¨‹çš„æ´å¯Ÿ"""
        insights = {
            'expert_usage_evolution': self.expert_usage_history,
            'loss_components_evolution': self.loss_history
        }
        
        if self.expert_usage_history:
            # åˆ†æä¸“å®¶ä½¿ç”¨çš„æ¼”åŒ–è¶‹åŠ¿
            final_usage = self.expert_usage_history[-1] if self.expert_usage_history else {}
            initial_usage = self.expert_usage_history[0] if self.expert_usage_history else {}
            
            usage_change = {}
            for expert in ['cnn', 'lstm', 'mamba', 'transformer']:
                final_pct = final_usage.get(expert, 0)
                initial_pct = initial_usage.get(expert, 0)
                usage_change[expert] = final_pct - initial_pct
            
            insights['usage_change'] = usage_change
        
        return insights