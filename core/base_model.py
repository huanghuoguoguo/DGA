#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DGA Detection - æ¨¡å‹åŸºç±»
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import numpy as np
import time
from typing import Dict, Any, Tuple
from abc import ABC, abstractmethod
from tqdm import tqdm


class BaseModel(nn.Module, ABC):
    """æ‰€æœ‰DGAæ£€æµ‹æ¨¡å‹çš„åŸºç±»"""
    
    def __init__(self, vocab_size: int, num_classes: int = 2):
        super(BaseModel, self).__init__()
        self.vocab_size = vocab_size
        self.num_classes = num_classes
    
    @abstractmethod
    def forward(self, x):
        """å‰å‘ä¼ æ’­ï¼Œå­ç±»å¿…é¡»å®ç°"""
        pass
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        return {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'model_size_mb': total_params * 4 / 1024 / 1024,
            'vocab_size': self.vocab_size,
            'num_classes': self.num_classes
        }
    
    def print_model_info(self):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
        info = self.get_model_info()
        print(f"ğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
        print(f"  æ€»å‚æ•°é‡: {info['total_params']:,}")
        print(f"  å¯è®­ç»ƒå‚æ•°: {info['trainable_params']:,}")
        print(f"  æ¨¡å‹å¤§å°: {info['model_size_mb']:.2f} MB")
        print(f"  è¯æ±‡è¡¨å¤§å°: {info['vocab_size']}")
        print(f"  ç±»åˆ«æ•°: {info['num_classes']}")


class ModelTrainer:
    """ç»Ÿä¸€çš„æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, model: BaseModel, device: str = 'cpu'):
        self.model = model
        self.device = device
        self.model.to(device)
    
    def train(self, 
              train_loader: DataLoader,
              val_loader: DataLoader,
              num_epochs: int = 20,
              learning_rate: float = 0.001,
              weight_decay: float = 1e-4,
              patience: int = 5,
              save_path: str = None) -> Dict[str, Any]:
        """è®­ç»ƒæ¨¡å‹"""
        
        optimizer = optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)
        criterion = nn.CrossEntropyLoss()
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=3)
        
        best_val_acc = 0
        patience_counter = 0
        training_history = {'train_acc': [], 'val_acc': [], 'train_loss': [], 'val_loss': []}
        
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ {self.model.__class__.__name__}...")
        start_time = time.time()
        
        for epoch in range(1, num_epochs + 1):
            # è®­ç»ƒé˜¶æ®µ
            train_metrics = self._train_epoch(train_loader, optimizer, criterion)
            
            # éªŒè¯é˜¶æ®µ
            val_metrics = self._validate_epoch(val_loader, criterion)
            
            # è®°å½•å†å²
            training_history['train_acc'].append(train_metrics['accuracy'])
            training_history['val_acc'].append(val_metrics['accuracy'])
            training_history['train_loss'].append(train_metrics['loss'])
            training_history['val_loss'].append(val_metrics['loss'])
            
            print(f"Epoch {epoch}/{num_epochs}: "
                  f"Train Acc: {train_metrics['accuracy']:.2f}%, "
                  f"Val Acc: {val_metrics['accuracy']:.2f}%, "
                  f"Train Loss: {train_metrics['loss']:.4f}, "
                  f"Val Loss: {val_metrics['loss']:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_metrics['accuracy'] > best_val_acc:
                best_val_acc = val_metrics['accuracy']
                patience_counter = 0
                if save_path:
                    torch.save(self.model.state_dict(), save_path)
                    print(f"  âœ… æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%ï¼Œæ¨¡å‹å·²ä¿å­˜")
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print(f"éªŒè¯å‡†ç¡®ç‡è¿ç»­{patience}ä¸ªepochæœªæå‡ï¼Œæå‰åœæ­¢è®­ç»ƒ")
                    break
            
            scheduler.step(val_metrics['accuracy'])
        
        training_time = time.time() - start_time
        print(f"è®­ç»ƒå®Œæˆï¼ç”¨æ—¶: {training_time:.2f}ç§’")
        
        return {
            'best_val_accuracy': best_val_acc,
            'training_time': training_time,
            'training_history': training_history,
            'final_epoch': epoch
        }
    
    def _train_epoch(self, train_loader: DataLoader, optimizer, criterion) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for data, target in tqdm(train_loader, desc="Training", leave=False):
            data, target = data.to(self.device), target.to(self.device)
            
            optimizer.zero_grad()
            output = self.model(data)
            loss = criterion(output, target)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            total_loss += loss.item()
            pred = output.argmax(dim=1)
            correct += pred.eq(target).sum().item()
            total += target.size(0)
        
        return {
            'loss': total_loss / len(train_loader),
            'accuracy': 100. * correct / total
        }
    
    def _validate_epoch(self, val_loader: DataLoader, criterion) -> Dict[str, float]:
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in tqdm(val_loader, desc="Validation", leave=False):
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                loss = criterion(output, target)
                
                total_loss += loss.item()
                pred = output.argmax(dim=1)
                correct += pred.eq(target).sum().item()
                total += target.size(0)
        
        return {
            'loss': total_loss / len(val_loader),
            'accuracy': 100. * correct / total
        }
    
    def evaluate(self, test_loader: DataLoader) -> Dict[str, Any]:
        """è¯„ä¼°æ¨¡å‹"""
        print(f"ğŸ“Š è¯„ä¼°æ¨¡å‹...")
        
        self.model.eval()
        all_preds = []
        all_targets = []
        inference_times = []
        
        with torch.no_grad():
            for data, target in tqdm(test_loader, desc="Evaluating"):
                data, target = data.to(self.device), target.to(self.device)
                
                # æµ‹é‡æ¨ç†æ—¶é—´
                start_time = time.time()
                output = self.model(data)
                inference_time = time.time() - start_time
                inference_times.append(inference_time)
                
                pred = output.argmax(dim=1)
                all_preds.extend(pred.cpu().numpy())
                all_targets.extend(target.cpu().numpy())
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(all_targets, all_preds)
        precision = precision_score(all_targets, all_preds, average='weighted')
        recall = recall_score(all_targets, all_preds, average='weighted')
        f1 = f1_score(all_targets, all_preds, average='weighted')
        avg_inference_time = np.mean(inference_times) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        results = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'inference_time_ms': avg_inference_time
        }
        
        print(f"  å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"  ç²¾ç¡®ç‡: {precision:.4f}")
        print(f"  å¬å›ç‡: {recall:.4f}")
        print(f"  F1åˆ†æ•°: {f1:.4f}")
        print(f"  å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.2f}ms")
        
        return results