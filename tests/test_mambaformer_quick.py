#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MambaFormer å¿«é€Ÿæµ‹è¯•
"""

import torch
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)

from models.implementations.mambaformer_model import MambaFormerModel

def quick_test():
    print("ğŸš€ MambaFormerå¿«é€Ÿæµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•å‚æ•°
    vocab_size = 40
    seq_length = 20
    batch_size = 2
    
    print("ğŸ“‹ MambaFormeræ¶æ„ç‰¹ç‚¹:")
    print("  â€¢ ç»“åˆMambaçŠ¶æ€ç©ºé—´æ¨¡å‹å’ŒTransformer")
    print("  â€¢ ä¸‰ç§èåˆç­–ç•¥: Sequential, Parallel, Gated")
    print("  â€¢ Mamba: çº¿æ€§å¤æ‚åº¦ + é€‰æ‹©æ€§æœºåˆ¶")
    print("  â€¢ Transformer: å…¨å±€æ³¨æ„åŠ› + å¹¶è¡Œè®¡ç®—")
    
    print(f"\nğŸ§ª æµ‹è¯•ä¸åŒèåˆç­–ç•¥:")
    
    for fusion_type in ['sequential', 'parallel', 'gated']:
        try:
            print(f"\n  {fusion_type.upper()}:")
            
            # åˆ›å»ºæ¨¡å‹
            model = MambaFormerModel(
                vocab_size=vocab_size,
                d_model=64,
                n_layers=2,
                d_state=16,
                n_heads=4,
                fusion_type=fusion_type
            )
            
            # æ¨¡å‹ä¿¡æ¯
            total_params = sum(p.numel() for p in model.parameters())
            print(f"    å‚æ•°é‡: {total_params:,}")
            
            # å‰å‘ä¼ æ’­æµ‹è¯•
            x = torch.randint(0, vocab_size, (batch_size, seq_length))
            
            with torch.no_grad():
                output = model(x)
            
            print(f"    è¾“å…¥: {x.shape} â†’ è¾“å‡º: {output.shape}")
            print(f"    è¾“å‡ºèŒƒå›´: [{output.min().item():.3f}, {output.max().item():.3f}]")
            print(f"    âœ… æˆåŠŸ")
            
        except Exception as e:
            print(f"    âŒ å¤±è´¥: {e}")
    
    print(f"\nğŸ’¡ MambaFormerä¼˜åŠ¿:")
    print("  1. ç»“åˆçº¿æ€§å¤æ‚åº¦å’Œå…¨å±€æ³¨æ„åŠ›")
    print("  2. é€‚åˆé•¿åºåˆ—å¤„ç†ï¼ˆåŸŸåå¯èƒ½å¾ˆé•¿ï¼‰")
    print("  3. çµæ´»çš„èåˆç­–ç•¥é€‰æ‹©")
    print("  4. åœ¨DGAæ£€æµ‹ä¸­å¹³è¡¡æ•ˆç‡å’Œå‡†ç¡®ç‡")
    
    print(f"\nğŸ¯ æ¨èç”¨æ³•:")
    print("  python main.py train --model mambaformer --quick")
    print("  python main.py analyze --chart")

if __name__ == "__main__":
    quick_test()