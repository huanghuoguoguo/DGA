#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DGA Detection - å¿«é€Ÿæµ‹è¯•è„šæœ¬
éªŒè¯é‡æ„åçš„é¡¹ç›®æ˜¯å¦èƒ½æ­£å¸¸è¿è¡Œ
"""

import torch
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)

def test_imports():
    """æµ‹è¯•æ‰€æœ‰æ¨¡å—æ˜¯å¦èƒ½æ­£å¸¸å¯¼å…¥"""
    print("ğŸ” æµ‹è¯•æ¨¡å—å¯¼å…¥...")
    
    try:
        from core.dataset import create_data_loaders, print_dataset_info
        print("  âœ… core.dataset")
    except Exception as e:
        print(f"  âŒ core.dataset: {e}")
        return False
    
    try:
        from core.base_model import BaseModel, ModelTrainer
        print("  âœ… core.base_model")
    except Exception as e:
        print(f"  âŒ core.base_model: {e}")
        return False
    
    try:
        from config.config import config
        print("  âœ… config.config")
    except Exception as e:
        print(f"  âŒ config.config: {e}")
        return False
    
    try:
        from models.implementations.cnn_model import CNNModel
        print("  âœ… models.implementations.cnn_model")
    except Exception as e:
        print(f"  âŒ models.implementations.cnn_model: {e}")
        return False
    
    try:
        from models.implementations.lstm_model import LSTMModel
        print("  âœ… models.implementations.lstm_model")
    except Exception as e:
        print(f"  âŒ models.implementations.lstm_model: {e}")
        return False
    
    try:
        from models.implementations.mamba_model import MambaModel
        print("  âœ… models.implementations.mamba_model")
    except Exception as e:
        print(f"  âŒ models.implementations.mamba_model: {e}")
        return False
    
    return True


def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("\\nğŸ“‚ æµ‹è¯•æ•°æ®åŠ è½½...")
    
    try:
        from core.dataset import load_dataset
        
        # å°è¯•åŠ è½½æ•°æ®é›†
        dataset_paths = [
            './data/processed/small_dga_dataset.pkl',
            './data/small_dga_dataset.pkl'
        ]
        
        dataset = None
        for path in dataset_paths:
            if os.path.exists(path):
                dataset = load_dataset(path)
                print(f"  âœ… æˆåŠŸåŠ è½½æ•°æ®é›†: {path}")
                break
        
        if dataset is None:
            print("  âš ï¸  æœªæ‰¾åˆ°æ•°æ®é›†æ–‡ä»¶")
            print("  å¯ç”¨çš„æ•°æ®é›†è·¯å¾„:")
            for path in dataset_paths:
                exists = "å­˜åœ¨" if os.path.exists(path) else "ä¸å­˜åœ¨"
                print(f"    {path}: {exists}")
            return False
        
        print(f"  ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"    æ ·æœ¬æ•°: {len(dataset['X'])}")
        print(f"    è¯æ±‡è¡¨å¤§å°: {dataset['vocab_size']}")
        print(f"    ç‰¹å¾ç»´åº¦: {dataset['X'].shape}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False


def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\\nğŸ—ï¸  æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    try:
        from models.implementations.cnn_model import CNNModel
        from models.implementations.lstm_model import LSTMModel
        from models.implementations.mamba_model import MambaModel
        
        vocab_size = 40  # æ¨¡æ‹Ÿè¯æ±‡è¡¨å¤§å°
        
        # æµ‹è¯•CNNæ¨¡å‹
        cnn_model = CNNModel(vocab_size=vocab_size, d_model=64)
        print(f"  âœ… CNNæ¨¡å‹åˆ›å»ºæˆåŠŸ, å‚æ•°é‡: {sum(p.numel() for p in cnn_model.parameters()):,}")
        
        # æµ‹è¯•LSTMæ¨¡å‹
        lstm_model = LSTMModel(vocab_size=vocab_size, d_model=64)
        print(f"  âœ… LSTMæ¨¡å‹åˆ›å»ºæˆåŠŸ, å‚æ•°é‡: {sum(p.numel() for p in lstm_model.parameters()):,}")
        
        # æµ‹è¯•Mambaæ¨¡å‹
        mamba_model = MambaModel(vocab_size=vocab_size, d_model=64, n_layers=2)
        print(f"  âœ… Mambaæ¨¡å‹åˆ›å»ºæˆåŠŸ, å‚æ•°é‡: {sum(p.numel() for p in mamba_model.parameters()):,}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False


def test_forward_pass():
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print("\\nâš¡ æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
    
    try:
        from models.implementations.cnn_model import CNNModel
        
        # åˆ›å»ºæ¨¡å‹å’Œè™šæ‹Ÿæ•°æ®
        vocab_size = 40
        seq_length = 20
        batch_size = 4
        
        model = CNNModel(vocab_size=vocab_size, d_model=64)
        
        # åˆ›å»ºè™šæ‹Ÿè¾“å…¥
        x = torch.randint(0, vocab_size, (batch_size, seq_length))
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            output = model(x)
        
        print(f"  âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"  è¾“å…¥å½¢çŠ¶: {x.shape}")
        print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"  è¾“å‡ºèŒƒå›´: [{output.min().item():.3f}, {output.max().item():.3f}]")
        
        return True
        
    except Exception as e:
        print(f"  âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ DGAæ£€æµ‹é¡¹ç›®é‡æ„éªŒè¯")
    print("=" * 50)
    
    tests = [
        ("æ¨¡å—å¯¼å…¥æµ‹è¯•", test_imports),
        ("æ•°æ®åŠ è½½æµ‹è¯•", test_data_loading),
        ("æ¨¡å‹åˆ›å»ºæµ‹è¯•", test_model_creation),
        ("å‰å‘ä¼ æ’­æµ‹è¯•", test_forward_pass)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\\nğŸ§ª {test_name}")
        if test_func():
            passed += 1
        
    print(f"\\n" + "=" * 50)
    print(f"ğŸ¯ æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é¡¹ç›®é‡æ„æˆåŠŸï¼")
        print("\\nğŸ“ æ¥ä¸‹æ¥å¯ä»¥:")
        print("  1. è¿è¡Œå¿«é€Ÿè®­ç»ƒæµ‹è¯•: python simple_train.py --model cnn --quick")
        print("  2. è®­ç»ƒæ‰€æœ‰æ¨¡å‹: python simple_train.py --all")
        print("  3. è®­ç»ƒç‰¹å®šæ¨¡å‹: python simple_train.py --model mamba")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        
    return passed == total


if __name__ == "__main__":
    main()